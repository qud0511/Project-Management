{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21a55de-bfd3-481c-9917-a96fb48231ce",
   "metadata": {},
   "source": [
    "# 플랫폼 업로드를 쉽게하기 위한 로컬 개발 코드\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): 빅데이터/인공지능 통합 플랫폼\n",
    "- 플랫폼 업로드를 쉽게하기 위하여 로컬에서 아래의 코드(파일1)를 개발한다.\n",
    "- 파일 1(파일명): 1_local_platform_image_classification.ipynb\n",
    "\n",
    "### 전처리 객체 또는 학습모델 객체\n",
    "- 전처리 객체나 학습모델 객체는 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "### 데이터셋(학습 데이터/테스트 데이터)\n",
    "- 학습과 테스트에 사용되는 데이터를 나누어 관리한다.\n",
    "- 학습 데이터: dataset 폴더 아래에 저장하거나 dataset.zip 파일 형태로 저장한다.\n",
    "- 테스트 데이터: test_dataset 폴더 아래에 저장하거나 test_dataset.zip 파일 형태로 저장한다.\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. 데이터셋 준비(Data Setup)\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터셋을 준비한다.\n",
    "\n",
    "2. 데이터 전처리(Data Preprocessing)\n",
    "- 데이터셋의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. 학습 모델 훈련(Train Model)\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터셋으로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. 추론(Inference)\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터셋을 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a49447-78e0-4d73-af2e-1747a610e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "#Image(filename='./T3Q.ai.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27499345-4512-444e-8c88-c8ad22a314fc",
   "metadata": {},
   "source": [
    "# 인공지능 통합플랫폼(T3Q.ai) 프로세스를 이해하고 인공지능 쉽게 하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f137ba3a-5ef5-408b-b768-50706d7e4ac7",
   "metadata": {},
   "source": [
    "1. 머신러닝(Machine Learning)과 딥러닝(Deep Learning) 프로그래밍 패턴\n",
    "\n",
    "(1) 데이터셋 불러오기(Dataset Loading)\n",
    "(2) 데이터 전처리(Data Preprocessing)\n",
    "   - 데이터 정규화(Normalization)\n",
    "   - 학습과 테스트 데이터 분할(Train/Test Data Split) 등\n",
    "(3) 학습 모델 구성(Train Model Build)\n",
    "(4) 학습(Model Training)\n",
    "(5) 학습 모델 성능 검증(Model Performance Validation)\n",
    "(6) 학습 모델 저장(배포) 하기(Model Save)\n",
    "(7) 추론 데이터 전처리((Data Preprocessing)\n",
    "(8) 추론(Inference) 또는 예측(Prediction) \n",
    "(9) 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "093fe2a0-6478-41a3-b0cd-91126412f286",
   "metadata": {},
   "source": [
    "2. 빅데이터/인공지능 통합 플랫폼[ T3Q.ai ]에서 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    " - 6개의 함수로 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    "\n",
    "(1) process_for_train(pm) 함수\n",
    " - 데이터셋 준비(Dataset Setup) \n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(2) init_svc(im, rule) 함수\n",
    " - 전처리 객체 불러오기\n",
    "   에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(3) transform(df, params, batch_id) 함수\n",
    "- 추론 데이터 전처리((Data Preprocessing)\n",
    "  에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(4) train(tm) 함수 \n",
    " - 데이터셋 불러오기(Dataset Loading)\n",
    " - 데이터 전처리(Data Preprocessing)\n",
    " - 학습 모델 구성(Train Model Build)\n",
    " - 학습(Model Training)\n",
    " - 학습 모델 성능 검증(Model Performance Validation)\n",
    " - 전처리 객체 저장\n",
    " - 학습 모델 저장(배포) 하기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(5) init_svc(im) 함수 \n",
    " - 전처리 객체 불러오기\n",
    " - 학습모델 객체 불러오기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(6) inference(df, params, batch_id) 함수\n",
    " - 추론 데이터 전처리((Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) \n",
    "   에 필요한 코드 작성"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b5db594-87d6-4a01-a9e9-788dfbf442cc",
   "metadata": {},
   "source": [
    "3. 전처리 모듈 관리, 학습 알고리즘 관리 함수 설명\n",
    "\n",
    "1) 프로젝트 설정/전처리모듈 관리 함수 \n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) 입력: pm\n",
    "      # pm.source_path: 학습플랫폼/데이터셋 관리 메뉴에서 저장한 데이터를 불러오는 경로\n",
    "      # pm.target_path: 처리 완료된 데이터를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터셋 관리 메뉴에서 저장한 데이터를 불러와서 필요한 처리를 수행\n",
    "      # 처리 완료된 데이터를 저장하는 기능, pm.target_path에 저장\n",
    "      # train(tm) 함수의 tm.train_data_path를 통해 데이터를 불러와서 전처리와 학습을 수행 \n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) 입력: im, rule\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # process_for_train(pm) 함수에서 저장한 전처리 객체와 데이터에 적용된 룰(rule)을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: 추론모델관리와 추론API관리, 실시간 추론을 통해 전달되는 추론 입력 데이터(dataframe 형태)\n",
    "      # params: init_svc(im, rule) 함수의 리턴(return) 값을 params 변수로 전달\n",
    "    (2) 출력: df\n",
    "    (3) 설명: \n",
    "      # df(추론 입력 데이터)에 대한 전처리를 수행한 후 전처리 된 데이터를 inference(df, ...) 함수의 입력 df에 전달하는 기능\n",
    "      # df(추론 입력 데이터)를 전처리 없이 inference(df, params, batch_id) 함수의 입력 df에 리턴(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "2) 프로젝트 설정/학습 알고리즘 관리 함수\n",
    "\n",
    "def train(tm):\n",
    "    \"\"\"\n",
    "    (1) 입력: tm\n",
    "      # tm.train_data_path: pm.target_path에 저장한 데이터를 불러오는 경로\n",
    "      # tm.model_path: 전처리 객체와 학습 모델 객체를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # pm.target_path에 저장한 데이터를 tm.train_data_path를 통해 데이터를 불러오는 기능\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 저장, tm.model_path에 저장\n",
    "      # init_svc(im) 함수의 im.model_path를 통해 전처리 객체와 학습 모델 객체를 준비\n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im):\n",
    "    \"\"\"\n",
    "    (1) 입력: im\n",
    "      # im.model_path: tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 경로\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference(df, params, batch_id) 함수의 입력 params 변수로 전달\n",
    "    \"\"\"\n",
    "\n",
    "    return { \"model\": model, \"param\": param }\n",
    "\n",
    "def inference(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: transform(df, params, batch_id)함수의 리턴(return) 값으로 전달된 df, 추론 입력 데이터(dataframe 형태)\n",
    "      # params  init_svc(im) 함수의 return 값을 params 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model=params['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca=params['pca']\n",
    "    (2) 출력: 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 df(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 df(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\"inference\": result}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70dd01f0-97f9-414f-9653-2b7dba5466fd",
   "metadata": {},
   "source": [
    "4. 전처리 모듈 관리, 학습 알고리즘 관리 함수 설명(AI 훈민정음 프로젝트)\n",
    "\n",
    "1) 프로젝트 설정/전처리모듈 관리 함수(AI 훈민정음 프로젝트) \n",
    "\n",
    "import logging\n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) 입력: pm\n",
    "      # pm.source_path: 학습플랫폼/데이터셋 관리 메뉴에서 저장한 데이터를 불러오는 경로\n",
    "      # pm.target_path: 처리 완료된 데이터를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터셋 관리 메뉴에서 저장한 데이터를 불러와서 필요한 처리를 수행\n",
    "      # 처리 완료된 데이터를 저장하는 기능, pm.target_path에 저장\n",
    "      # train(tm) 함수의 tm.train_data_path를 통해 데이터를 불러와서 전처리와 학습을 수행 \n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_process)로 정의하여 사용함\n",
    "      # 함수명                            서브함수명\n",
    "      # process_for_train(pm)          exec_process(pm) \n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행\n",
    "    \"\"\"\n",
    "\n",
    "    exec_process(pm)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) 입력: im, rule\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # process_for_train(pm) 함수에서 저장한 전처리 객체와 데이터에 적용된 룰(rule)을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: 추론모델관리와 추론API관리, 실시간 추론을 통해 전달되는 추론 입력 데이터(dataframe 형태)\n",
    "      # params: init_svc(im, rule) 함수의 리턴(return) 값을 params 변수로 전달\n",
    "    (2) 출력: df\n",
    "    (3) 설명: \n",
    "      # df(추론 입력 데이터)에 대한 전처리를 수행한 후 전처리 된 데이터를 inference(df, ...) 함수의 입력 df에 전달하는 기능\n",
    "      # df(추론 입력 데이터)를 전처리 없이 inference(df, params, batch_id) 함수의 입력 df에 리턴(return)\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행            \n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "2) 프로젝트 설정/학습 알고리즘 관리 함수(AI 훈민정음 프로젝트)\n",
    "\n",
    "import logging\n",
    "\n",
    "def train(tm):\n",
    "    \"\"\"\n",
    "    (1) 입력: tm\n",
    "      # tm.train_data_path: pm.target_path에 저장한 데이터를 불러오는 경로\n",
    "      # tm.model_path: 전처리 객체와 학습 모델 객체를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # pm.target_path에 저장한 데이터를 tm.train_data_path를 통해 데이터를 불러오는 기능\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 저장, tm.model_path에 저장\n",
    "      # init_svc(im) 함수의 im.model_path를 통해 전처리 객체와 학습 모델 객체를 준비\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_train)로 정의하여 사용함\n",
    "      # 함수명                         서브함수명\n",
    "      # train(tm)                      exec_train(tm)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행\n",
    "    \"\"\"\n",
    "\n",
    "    exec_train(tm)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "def init_svc(im):\n",
    "    \"\"\"\n",
    "    (1) 입력: im\n",
    "      # im.model_path: tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 경로\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference(df, params, batch_id) 함수의 입력 params 변수로 전달\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_init_svc)로 정의하여 사용함\n",
    "      # 함수명                            서브함수명\n",
    "      # init_svc(im)                      exec_init_svc(im)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행      \n",
    "    \"\"\"\n",
    "\n",
    "    params = exec_init_svc(im)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [init_svc]')\n",
    "    \n",
    "    return { **params }\n",
    "\n",
    "def inference(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: transform(df, params, batch_id)함수의 리턴(return) 값으로 전달된 df, 추론 입력 데이터(dataframe 형태)\n",
    "      # params  init_svc(im) 함수의 return 값을 params 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model=params['model']\n",
    "        ## 전처리 객체 사용 예시          pca=params['pre_model']\n",
    "    (2) 출력: 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 df(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 df(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_inference)로 정의하여 사용함\n",
    "      # 함수명                                                     서브함수명\n",
    "      # inference(df, params, batch_id)                      exec_inference(df, params, batch_id)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행            \n",
    "    \"\"\"\n",
    "    \n",
    "    result = exec_inference(df, params, batch_id)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [inference]')\n",
    "\n",
    "    return { **result }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f8718-0eda-41a6-a83e-7464a3c494c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c151c56-513c-44a5-9e13-fd154883b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명: image_classification_preprocess.py\n",
    "\n",
    "'''\n",
    "from image_classification_preprocess_sub import exec_process\n",
    "'''\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def process_for_train(pm):\n",
    "    \n",
    "    exec_process(pm)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "    \n",
    "    \n",
    "def init_svc(im, rule):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \n",
    "    logging.info('[hunmin log] df : {}'.format(df))\n",
    "    logging.info('[hunmin log] df.shape : {}'.format(df.shape))\n",
    "    logging.info('[hunmin log] type(df) : {}'.format(type(df)))   \n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a6e7b5-37a9-40bb-bede-54ac21c5568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# 파일명: image_classification_preprocess_sub.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "\n",
    "def exec_process(pm):\n",
    "\n",
    "    logging.info('[hunmin log]  the start line of the function [exec_process]')\n",
    "\n",
    "    logging.info('[hunmin log] pm.source_path : {}'.format(pm.source_path))\n",
    "\n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.source_path)\n",
    "    \n",
    "    # pm.source_path의 dataset.zip 파일을 \n",
    "    # pm.target_path의 dataset 폴더에 압축을 풀어준다.\n",
    "    my_zip_path = os.path.join(pm.source_path,'dataset.zip')\n",
    "    extract_zip_file = zipfile.ZipFile(my_zip_path)\n",
    "    extract_zip_file.extractall(pm.target_path)\n",
    "    extract_zip_file.close()\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.target_path)\n",
    "\n",
    "    logging.info('[hunmin log]  the finish line of the function [exec_process]')\n",
    "\n",
    "\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a377ae8-1201-46fa-96eb-547a8ddd6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명: image_classification_train.py\n",
    "\n",
    "'''\n",
    "from image_classification_train_sub import exec_train, exec_init_svc, exec_inference\n",
    "'''\n",
    "import logging\n",
    "\n",
    "\n",
    "def train(tm):\n",
    "    \n",
    "    exec_train(tm)\n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "\n",
    "def init_svc(im):\n",
    "    \n",
    "    params = exec_init_svc(im)\n",
    "    logging.info('[hunmin log] the end line of the function [init_svc]')\n",
    "    \n",
    "    return { **params }\n",
    "\n",
    "\n",
    "def inference(df, params, batch_id):\n",
    "    \n",
    "    result = exec_inference(df, params, batch_id)\n",
    "    logging.info('[hunmin log] the end line of the function [inference]')\n",
    "    \n",
    "    return { **result }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ccb934-12d1-4071-9a9c-e26ce1a66548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] tensorflow ver : 2.9.0\n",
      "INFO:root:[hunmin log] gpu set complete\n",
      "INFO:root:[hunmin log] num of gpu: 1\n"
     ]
    }
   ],
   "source": [
    "# 파일명: image_classification_train_sub.py\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "import logging\n",
    "import base64 \n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "logging.info(f'[hunmin log] tensorflow ver : {tf.__version__}')\n",
    "\n",
    "# 사용할 gpu 번호를 적는다.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "        logging.info('[hunmin log] gpu set complete')\n",
    "        logging.info('[hunmin log] num of gpu: {}'.format(len(gpus)))\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        logging.info('[hunmin log] gpu set failed')\n",
    "        logging.info(e)\n",
    "        \n",
    "        \n",
    "def exec_train(tm):\n",
    "    \n",
    "    logging.info('[hunmin log] the start line of the function [exec_train]')\n",
    "    \n",
    "    logging.info('[hunmin log] tm.train_data_path : {}'.format(tm.train_data_path))\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(tm.train_data_path)\n",
    "    \n",
    "    ###########################################################################\n",
    "    ## 1. 데이터셋 준비(Data Setup)\n",
    "    ###########################################################################\n",
    "    \n",
    "    my_path = os.path.join(tm.train_data_path, 'dataset') + '/'\n",
    "    \n",
    "    # 카테고리\n",
    "    dataset=['ant','apple', 'bus', 'butterfly', 'cup', 'envelope','fish', 'giraffe', 'lightbulb','pig']\n",
    "    dataset_num= len(dataset) #10\n",
    "\n",
    "    # 경로에 있는 numpy를 load하고 dataset_numpy list에 추가한다. \n",
    "    dataset_numpy = []\n",
    "    for i in range (dataset_num):\n",
    "        ad = my_path + str(dataset[i]) +'.npy'\n",
    "        dataset_numpy.append(np.load(ad))\n",
    "   \n",
    "    logging.info('[hunmin log] : (image_number, image_size)')\n",
    "    \n",
    "    for i in range (dataset_num):\n",
    "        logging.info('[hunmin log] : {}'.format(dataset_numpy[i].shape))\n",
    "    \n",
    "        \n",
    "    np.set_printoptions(linewidth=116)\n",
    "    # dataset_numpy[5] 가 envelope numpy 이다.    \n",
    "    logging.info('[hunmin log] envelope : ')\n",
    "    logging.info('{}'.format(dataset_numpy[5][0]))\n",
    "    \n",
    "    ###########################################################################\n",
    "    ## 2. 데이터 전처리(Data Preprocessing)\n",
    "    ###########################################################################\n",
    "\n",
    "    # 카테고리별로 같은 수의 이미지를 훈련시키기 위해 훈련시키고자 하는 이미지의 개수를 정해준다.\n",
    "    idx = 1000\n",
    "    \n",
    "    # 데이터 정규화 (Normalization) & 데이터 합치기 & 레이블 생성\n",
    "    # X: 입력 이미지 배열 데이터\n",
    "    # Y: 정답 레이블 데이터\n",
    "    # 정규화 및 정답 레이블 생성\n",
    "    X = np.array([data_numpy[:idx, :]/255. for data_numpy in dataset_numpy]).astype('float32')\n",
    "    X = X.reshape(-1, 28*28)\n",
    "    Y = np.array([i for i in range(10) for j in range(idx)]).astype('float32')\n",
    "\n",
    "    # 훈련 & 평가 데이터셋 생성\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "\n",
    "    # 모델 훈련에 사용할 수 있는 형태로 변경\n",
    "    # X의 값을 [samples][pixels][width][height] 형태로 reshape한다.\n",
    "    X_train_cnn = X_train.reshape(X_train.shape[0], 28, 28 , 1).astype('float32')\n",
    "    X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28 , 1).astype('float32')\n",
    "    \n",
    "    # reshape된 결과 확인 및 원래 배열의 형태와 비교\n",
    "    logging.info('[hunmin log] X_train : {}'.format(X_train.shape))\n",
    "    logging.info('[hunmin log] X_train_cnn : {}'.format(X_train_cnn.shape))\n",
    "\n",
    "    \n",
    "    # Y의 배열에 one-hot-encoding 진행\n",
    "    Y_train_cnn = utils.to_categorical(Y_train)\n",
    "    Y_test_cnn = utils.to_categorical(Y_test)\n",
    "    num_classes = Y_test_cnn.shape[1] # class는 총 10개이다.\n",
    "\n",
    "    # encoding된 결과 확인 및 원래 배열의 형태와 비교\n",
    "    logging.info('[hunmin log] Y_train : {}'.format(Y_train.shape))\n",
    "    logging.info('[hunmin log] Y_train_cnn : {}'.format(Y_train_cnn.shape))\n",
    "    logging.info('[hunmin log] class number : {}'.format(num_classes))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################################################################\n",
    "    ## 3. 학습 모델 훈련(Train Model)\n",
    "    ###########################################################################\n",
    "\n",
    "    # 모델 구축 (Build Model)\n",
    "    # 이미지 분류를 위해 아주 간단한 CNN 모델을 Keras를 이용하여 구축하고자 한다.\n",
    "    \n",
    "    # 단일 gpu 혹은 cpu학습\n",
    "    if len(gpus) < 2:\n",
    "        model = model_build_and_compile(num_classes)\n",
    "    # multi-gpu\n",
    "    else:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        logging.info('[hunmin log] gpu devices num {}'.format(strategy.num_replicas_in_sync))\n",
    "        with strategy.scope():\n",
    "            model = model_build_and_compile(num_classes)\n",
    "\n",
    "    # 사용자 입력 파라미터\n",
    "    batch_size = int(tm.param_info['batch_size'])\n",
    "    epochs = int(tm.param_info['epoch'])\n",
    "\n",
    "    # gpu에 따른 batch_size 설정\n",
    "    batch_size = batch_size * len(gpus) if len(gpus) > 0 else batch_size\n",
    "\n",
    "    # 모델 학습 (Train Model)\n",
    "    history = model.fit(X_train_cnn, Y_train_cnn, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        validation_split=0.1, \n",
    "                        verbose=0, \n",
    "                        callbacks=[LossAndErrorPrintingCallback()]\n",
    "                       )\n",
    "    \n",
    "    # 모델 평가 (Evaluate Model)\n",
    "    loss, acc = model.evaluate(X_test_cnn, Y_test_cnn, verbose=0, callbacks=[LossAndErrorPrintingCallback()])\n",
    "    \n",
    "    logging.info('[hunmin log] loss : {}'.format(loss))\n",
    "    logging.info('[hunmin log] acc : {}'.format(acc))\n",
    "    \n",
    "\n",
    "    ###########################################################################\n",
    "    ## 플랫폼 시각화\n",
    "    ###########################################################################  \n",
    "    '''\n",
    "    plot_metrics(tm, history, model, X_test_cnn, Y_test_cnn)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ###########################################################################\n",
    "    ## 학습 모델 저장\n",
    "    ###########################################################################\n",
    "    \n",
    "    logging.info('[hunmin log] tm.model_path : {}'.format(tm.model_path))\n",
    "    model.save(os.path.join(tm.model_path, 'cnn_model.h5'))\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(tm.model_path)\n",
    "    \n",
    "    logging.info('[hunmin log]  the finish line of the function [exec_train]')\n",
    "    \n",
    "\n",
    "\n",
    "def exec_init_svc(im):\n",
    "\n",
    "    logging.info('[hunmin log] im.model_path : {}'.format(im.model_path))\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(im.model_path)\n",
    "    \n",
    "    ###########################################################################\n",
    "    ## 학습 모델 준비\n",
    "    ########################################################################### \n",
    "    \n",
    "    # load the model\n",
    "    model = load_model(os.path.join(im.model_path, 'cnn_model.h5'))\n",
    "    \n",
    "    return {'model' : model}\n",
    "\n",
    "\n",
    "\n",
    "def exec_inference(df, params, batch_id):\n",
    "    \n",
    "    ###########################################################################\n",
    "    ## 4. 추론(Inference)\n",
    "    ###########################################################################\n",
    "    \n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference]')\n",
    "    \n",
    "    ## 학습 모델 준비\n",
    "    model = params['model']\n",
    "    logging.info('[hunmin log] model.summary() :')\n",
    "    model.summary(print_fn=logging.info)\n",
    "    \n",
    "    dataset=['ant','apple', 'bus', 'butterfly', 'cup', 'envelope','fish', 'giraffe', 'lightbulb','pig']\n",
    "    \n",
    "    # image preprocess\n",
    "    img_base64 = df.iloc[0, 0]\n",
    "    image_bytes = io.BytesIO(base64.b64decode(img_base64))\n",
    "    image = Image.open(image_bytes).convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "    image = np.invert(image).astype('float32')/255.\n",
    "    image = image.reshape(-1, 28, 28 , 1)\n",
    "    \n",
    "    # data predict\n",
    "    y_pred = model.predict(image)\n",
    "    y_pred_idx=np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # inverse transform\n",
    "    result = {'inference' : dataset[y_pred_idx[0]]}\n",
    "    logging.info('[hunmin log] result : {}'.format(result))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "## exec_train(tm) 호출 함수 \n",
    "###########################################################################\n",
    "\n",
    "# for epoch, loss\n",
    "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        #logging.info(\"For epoch {}, loss is {:.2f}, acc is {:.2f}.\".format(batch, logs.get('loss'), logs.get('acc')))\n",
    "        logging.info('[hunmin log] For epoch {}, loss is {:.2f}.'.format(batch+1, logs['loss']))\n",
    "\n",
    "def model_build_and_compile(num_classes):\n",
    "    #모델 구축\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(28,28,1)),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "    logging.info('[hunmin log] model.summary() :')\n",
    "    model.summary(print_fn=logging.info)\n",
    "    \n",
    "    # 모델 컴파일 (Compile Model)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# 시각화\n",
    "def plot_metrics(tm, history, model, x_test, y_test):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    accuracy_list = history.history['accuracy']\n",
    "    loss_list = history.history['loss']\n",
    "    \n",
    "    for step, (acc, loss) in enumerate(zip(accuracy_list, loss_list)):\n",
    "        metric={}\n",
    "        metric['accuracy'] = acc\n",
    "        metric['loss'] = loss\n",
    "        metric['step'] = step\n",
    "        tm.save_stat_metrics(metric)\n",
    "\n",
    "    predict_y = np.argmax(model.predict(x_test), axis = 1).tolist()\n",
    "    actual_y = np.argmax(y_test, axis = 1).tolist()\n",
    "    \n",
    "    eval_results={}\n",
    "    eval_results['predict_y'] = predict_y\n",
    "    eval_results['actual_y'] = actual_y\n",
    "    eval_results['accuracy'] = history.history['val_accuracy'][-1]\n",
    "    eval_results['loss'] = history.history['val_loss'][-1]\n",
    "\n",
    "    # calculate_confusion_matrix(eval_results)\n",
    "    eval_results['confusion_matrix'] = confusion_matrix(actual_y, predict_y).tolist()\n",
    "    tm.save_result_metrics(eval_results)\n",
    "    logging.info('[hunmin log] accuracy and loss curve plot for platform')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2227e4f-4e87-4c28-a467-969f5ca63761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm.source_path: ./\n",
      "pm.target_path:  ./meta_data\n",
      "tm.train_data_path:  ./meta_data\n",
      "tm.model_path:  ./meta_data\n",
      "tm.param_info['batch_size']:  10\n",
      "tm.param_info['epoch']:  20\n",
      "im.model_path:  ./meta_data\n",
      "df:                                                     0\n",
      "0  iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAA...\n",
      "df.dtypes: 0    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1, step=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PM 클래스: pm 객체\n",
    "class PM:\n",
    "    def __init__(self):\n",
    "        self.source_path = './'\n",
    "        self.target_path = './meta_data'\n",
    "\n",
    "# TM 클래스: tm 객체\n",
    "class TM:\n",
    "    param_info = {}\n",
    "    def __init__(self):\n",
    "        self.train_data_path = './meta_data'\n",
    "        self.model_path = './meta_data'\n",
    "        self.param_info['batch_size'] = 10\n",
    "        self.param_info['epoch'] = 20\n",
    "\n",
    "# IM 클래스: im 객체\n",
    "class IM:\n",
    "    def __init__(self):\n",
    "        self.model_path = './meta_data'\n",
    "\n",
    "\n",
    "# pm 객체\n",
    "pm = PM()\n",
    "print('pm.source_path:', pm.source_path)\n",
    "print('pm.target_path: ', pm.target_path)\n",
    "\n",
    "# tm 객체\n",
    "tm = TM()\n",
    "print('tm.train_data_path: ', tm.train_data_path)\n",
    "print('tm.model_path: ', tm.model_path)\n",
    "print('tm.param_info[\\'batch_size\\']: ', tm.param_info['batch_size'])\n",
    "print('tm.param_info[\\'epoch\\']: ', tm.param_info['epoch'])\n",
    "\n",
    "# im 객체\n",
    "im = IM()\n",
    "print('im.model_path: ', im.model_path)\n",
    "\n",
    "# inferecne(df, params, batch_id) 함수 입력\n",
    "params = {}\n",
    "batch_id = 0\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# base64 encoded image\n",
    "data = [['iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAACySURBVEhL7ZLRDoAgCEWt//9nc8EIEepStvXQeWkyPEKw1FrLbFb+TuWXzichXXb4cAokJR0tH+JFK21G8V6CSqlApMxGelBIsVBHeOOEzZYGdRzpussfL7eIazHPa0wrx0GMdBSiuMbkdINyb5og0gRL3dTbcPtNOpYZveQ2pA1n0hTakF5+hA9Lzd87pNFYLhkvsvT2lMhorndluxkRUuCYbzcp9ROi55+up8sLK1XKBj1wbx3DelAOAAAAAElFTkSuQmCC']]\n",
    "df = pd.DataFrame(data)\n",
    "print('df: ', df)\n",
    "print('df.dtypes:', df.dtypes)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a094ccf-6a82-4593-9dae-1134fbdb5a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log]  the start line of the function [exec_process]\n",
      "INFO:root:[hunmin log] pm.source_path : ./\n",
      "INFO:root:[hunmin log] Files and directories in ./ :\n",
      "INFO:root:[hunmin log] dir_list : ['0_local_image_classification.ipynb', '0_local_image_classification_requirement.txt', '1_local_platform_image_classification.ipynb', '2_1_1_platform_image_classification_preprocess.py', '2_1_2_platform_image_classification_preprocess_sub.py', '2_2_1_platform_image_classification_train.py', '2_2_2_platform_image_classification_train_sub.py', 'dataset.zip', 'LICENSE.txt', 'meta_data', 'README.txt', 'T3Q.ai_platform_image_classification', 'test_dataset.zip']\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset']\n",
      "INFO:root:[hunmin log]  the finish line of the function [exec_process]\n",
      "INFO:root:[hunmin log] the end line of the function [process_for_train]\n",
      "INFO:root:[hunmin log] the start line of the function [exec_train]\n",
      "INFO:root:[hunmin log] tm.train_data_path : ./meta_data\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset']\n",
      "INFO:root:[hunmin log] : (image_number, image_size)\n",
      "INFO:root:[hunmin log] : (124612, 784)\n",
      "INFO:root:[hunmin log] : (144722, 784)\n",
      "INFO:root:[hunmin log] : (166208, 784)\n",
      "INFO:root:[hunmin log] : (117999, 784)\n",
      "INFO:root:[hunmin log] : (130721, 784)\n",
      "INFO:root:[hunmin log] : (134863, 784)\n",
      "INFO:root:[hunmin log] : (134150, 784)\n",
      "INFO:root:[hunmin log] : (127182, 784)\n",
      "INFO:root:[hunmin log] : (120879, 784)\n",
      "INFO:root:[hunmin log] : (186770, 784)\n",
      "INFO:root:[hunmin log] envelope : \n",
      "INFO:root:[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11  17  26  34  34  37  51  51  51  66 112 123   1   0\n",
      "   0   0   0   0   0   0   1  29  63  97 132 166 200 235 255 255 255 255 255 255 255 255 255 255 255 255 117   0\n",
      "   0  12  78 138 180 215 248 255 255 255 247 213 179 145 110 102 102  85  85  85  74  68  68  69 215 255 101   0\n",
      "   0 122 255 249 199 164 130  96  61  27   1   0   0   0   0   0   0   0   0   0   0   0   1 164 252 255  94   0\n",
      "   0 120 255 250  59   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 115 255 116 255 113   0\n",
      "   0 116 255 213 230  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  30 245 165   0 255 121   0\n",
      "   0 113 255  44 239 198   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0 171 242  25   3 255 119   0\n",
      "   0 110 255  11  77 253 146   0   0   0   0   0   0   0   0   0   0   0   0   0  66 255 114   0   5 255 116   0\n",
      "   0 107 255  14   0 131 255  97   0   0   0   0   0   0   0   0   0   0   0   4 210 214   5   0   8 255 114   0\n",
      "   0 104 255  18   0   2 183 245  62   0   0   0   0   0   0   0   0   0   0 112 255  68   0   0  10 255 112   0\n",
      "   0  98 255  25   0   0  17 206 246  77   0   0   0   0   0   0   0   0  23 240 173   0   0   0  12 255 109   0\n",
      "   0  68 255  58   0   0   0  12 187 252  98   0   0   0   0   0   0   0 159 246  32   0   0   0  15 255 107   0\n",
      "   0  30 255  96   0   0   0   0   9 179 254 112   0   0   0   0   0  56 254 127   0   0   0   0  17 255 104   0\n",
      "   0   1 245 134   0   0   0   0   0   4 162 255 151   6   0   0   4 203 222   9   0   0   0   0  19 255 102   0\n",
      "   0   0 209 172   0   0   0   0   0   0   1 125 254 227 110   0 148 254  77   0   0   0  41 118 196 255  96   0\n",
      "   0   0 173 236 219 224 170 170 139  99  54  14  62 182 255 194 255 129  14  67 143 220 255 253 199 121  11   0\n",
      "   0   0 105 241 250 244 204 207 240 255 255 255 228 221 239 255 243 237 255 255 243 173  97  22   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  29  70 113 149 153 153 179 155 141 109  67   7   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "INFO:root:[hunmin log] X_train : (8000, 784)\n",
      "INFO:root:[hunmin log] X_train_cnn : (8000, 28, 28, 1)\n",
      "INFO:root:[hunmin log] Y_train : (8000,)\n",
      "INFO:root:[hunmin log] Y_train_cnn : (8000, 10)\n",
      "INFO:root:[hunmin log] class number : 10\n",
      "INFO:root:[hunmin log] model.summary() :\n",
      "INFO:root:Model: \"sequential\"\n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root: Layer (type)                Output Shape              Param #   \n",
      "INFO:root:=================================================================\n",
      "INFO:root: conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "INFO:root:                                                                 \n",
      "INFO:root: conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dropout (Dropout)           (None, 28, 28, 64)        0         \n",
      "INFO:root:                                                                 \n",
      "INFO:root: conv2d_2 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "INFO:root:                                                                 \n",
      "INFO:root: max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      "INFO:root: )                                                               \n",
      "INFO:root:                                                                 \n",
      "INFO:root: flatten (Flatten)           (None, 12544)             0         \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dense (Dense)               (None, 32)                401440    \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dropout_1 (Dropout)         (None, 32)                0         \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dense_1 (Dense)             (None, 10)                330       \n",
      "INFO:root:                                                                 \n",
      "INFO:root:=================================================================\n",
      "INFO:root:Total params: 457,514\n",
      "INFO:root:Trainable params: 457,514\n",
      "INFO:root:Non-trainable params: 0\n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:[hunmin log] For epoch 1, loss is 1.00.\n",
      "INFO:root:[hunmin log] For epoch 2, loss is 0.55.\n",
      "INFO:root:[hunmin log] For epoch 3, loss is 0.44.\n",
      "INFO:root:[hunmin log] For epoch 4, loss is 0.36.\n",
      "INFO:root:[hunmin log] For epoch 5, loss is 0.31.\n",
      "INFO:root:[hunmin log] For epoch 6, loss is 0.28.\n",
      "INFO:root:[hunmin log] For epoch 7, loss is 0.23.\n",
      "INFO:root:[hunmin log] For epoch 8, loss is 0.21.\n",
      "INFO:root:[hunmin log] For epoch 9, loss is 0.19.\n",
      "INFO:root:[hunmin log] For epoch 10, loss is 0.18.\n",
      "INFO:root:[hunmin log] For epoch 11, loss is 0.16.\n",
      "INFO:root:[hunmin log] For epoch 12, loss is 0.15.\n",
      "INFO:root:[hunmin log] For epoch 13, loss is 0.15.\n",
      "INFO:root:[hunmin log] For epoch 14, loss is 0.13.\n",
      "INFO:root:[hunmin log] For epoch 15, loss is 0.13.\n",
      "INFO:root:[hunmin log] For epoch 16, loss is 0.12.\n",
      "INFO:root:[hunmin log] For epoch 17, loss is 0.12.\n",
      "INFO:root:[hunmin log] For epoch 18, loss is 0.12.\n",
      "INFO:root:[hunmin log] For epoch 19, loss is 0.10.\n",
      "INFO:root:[hunmin log] For epoch 20, loss is 0.11.\n",
      "INFO:root:[hunmin log] loss : 0.626572847366333\n",
      "INFO:root:[hunmin log] acc : 0.8870000243186951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] tm.model_path : ./meta_data\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset']\n",
      "INFO:root:[hunmin log]  the finish line of the function [exec_train]\n",
      "INFO:root:[hunmin log] the end line of the function [train]\n",
      "INFO:root:[hunmin log] df :                                                    0\n",
      "0  iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAA...\n",
      "INFO:root:[hunmin log] df.shape : (1, 1)\n",
      "INFO:root:[hunmin log] type(df) : <class 'pandas.core.frame.DataFrame'>\n",
      "INFO:root:[hunmin log] the end line of the function [transform]\n",
      "INFO:root:[hunmin log] im.model_path : ./meta_data\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset']\n",
      "INFO:root:[hunmin log] the end line of the function [init_svc]\n",
      "INFO:root:[hunmin log] the start line of the function [exec_inference]\n",
      "INFO:root:[hunmin log] model.summary() :\n",
      "INFO:root:Model: \"sequential\"\n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root: Layer (type)                Output Shape              Param #   \n",
      "INFO:root:=================================================================\n",
      "INFO:root: conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "INFO:root:                                                                 \n",
      "INFO:root: conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dropout (Dropout)           (None, 28, 28, 64)        0         \n",
      "INFO:root:                                                                 \n",
      "INFO:root: conv2d_2 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "INFO:root:                                                                 \n",
      "INFO:root: max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      "INFO:root: )                                                               \n",
      "INFO:root:                                                                 \n",
      "INFO:root: flatten (Flatten)           (None, 12544)             0         \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dense (Dense)               (None, 32)                401440    \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dropout_1 (Dropout)         (None, 32)                0         \n",
      "INFO:root:                                                                 \n",
      "INFO:root: dense_1 (Dense)             (None, 10)                330       \n",
      "INFO:root:                                                                 \n",
      "INFO:root:=================================================================\n",
      "INFO:root:Total params: 457,514\n",
      "INFO:root:Trainable params: 457,514\n",
      "INFO:root:Non-trainable params: 0\n",
      "INFO:root:_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] result : {'inference': 'apple'}\n",
      "INFO:root:[hunmin log] the end line of the function [inference]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': 'apple'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "process_for_train(pm)\n",
    "\n",
    "train(tm)\n",
    "\n",
    "transform(df, params, batch_id)\n",
    "\n",
    "params = init_svc(im)\n",
    "\n",
    "inference(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f18ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
